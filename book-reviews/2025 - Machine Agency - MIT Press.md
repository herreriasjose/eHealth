
## 2025 Machine Agency Book Review

### Authors: James Mattingly and Beba Cibralic

### Publisher: Massachusetts Institute of Technology

## Key Conclusions

### What is **agency**?

**Agency**, in its most basic sense, is **the capacity to act**.

> "Agency, at its core, is the capacity to act."

However, it is not limited to mechanical motion. In a philosophical sense, **to act as an agent implies behaving guided by reasons**. For example, when Socrates chooses to remain in prison for moral reasons, he is not just physically remaining; he is acting as an agent. Thus, agency implies:

* **Activity** (doing something)
* **Sensitivity to changing conditions**
* And in some cases, **the use of internal representations** to guide action

The authors develop this notion into a more sophisticated theory, suitable for humans, animals, and potentially some machines.

---

### What is an **agent**?

An **agent** is a system that:

* Has an internal model of the world (including its own state)
* Uses those representations to **guide its behavior** toward goals
* Behaves adaptively and is not fully preprogrammed

> "Agents are systems that can represent the world (including their own states) and use their representations to guide their behaviors."

This distinguishes an agent from a tool:

* A tool **is used by an agent** and does not act on its own.
* An agent has **some functional autonomy** and decision-making capability.

---

### What is a **representation of the world**?

A representation of the world is, in general terms:

* A system that stands in for another system, in a way that guides the agent’s behavior in relation to that world.

#### Concrete examples

* Thermostat: has internal representations of the current and desired temperature. The heating or cooling action is guided by the discrepancy between these representations.

* GPS or navigation assistants: adjust behavior based on when the representation of the current position matches the destination representation.

In summary, within the framework of *Machine Agency*, a representation of the world is any internal state of a system that can:

* Capture meaningful information about the environment
* Be used to modulate or guide its behavior
* Not require the machine to “understand” that information; it is enough that it uses it functionally to act autonomously or adaptively

---

### Why focus on agency?

* **More useful than “intelligence”**: it allows us to evaluate impact and responsibility without assuming mind or consciousness.
* **Current machines** (AlphaGo, GPT, autonomous robots) already meet minimal criteria for agency.
* **No need for consciousness or mind**: it is enough that the system uses representations to guide behavior.
* **Not dependent on biological substrate**: what matters is functional organization, not whether it’s made of neurons or silicon.
* **Requires new ethical and legal norms**: agency implies taking responsibility for design, control, and social consequences.

---

### Minimalist theory of agency

The book’s central proposal:

> "An agent is a system that uses representations of the world (and of itself) to guide its behavior toward goals."

This framework allows the inclusion of:

* Humans and animals
* Machines with adaptive learning
* Computational systems with active environmental representation

This **does not imply mind, consciousness, or automatic moral rights**, but it **does demand renewed ethical and philosophical reflection**.

---

## Chapter-by-Chapter Review

### **Chapter 1: Orientation**

Presents the central question: what does it mean to be an agent? Why is agency more relevant than intelligence in AI discussions?

* Distinguishes between physical explanations (how something happens) and action explanations (why it happens).
* Suggests that some machines already **act on their own**.

---

### **Chapter 2: Myths of Machine Agents**

Analyzes foundational stories to explore cultural projection of agency:

* **Talos**: Greek automaton animated with “ichor.”
* **Frankenstein**: being that learns, suffers, and acts autonomously.
* **Ava (Ex Machina)**: android who manipulates to gain freedom.
* **Golem**: clay figure activated by symbols.

> These figures show how we attribute agency to the artificial, reflecting desires for control and fears of losing the human central role.

---

### **Chapter 3: Debates about Machine Minds**

Explores whether machines can have minds:

* Turing Test: imitation vs real understanding
* Searle’s Chinese Room: syntax ≠ semantics
* Risk of anthropomorphism

> Conclusion: **agency provides a clearer framework** than mind for evaluating the societal role of machines.

---

### **Chapter 4: Exploring Agency**

Reviews philosophical theories of agency:

* Belief-desire models
* Behavioral theories

Highlights the difficulty of defining agency without assuming mind or consciousness. Raises the question: can there be reasons without minds?

---

### **Chapter 5: A Minimalist Theory of Agency**

Defines the key concept of the book:

> “System that uses representations to guide goal-directed behavior.”

Advantages:

* Includes machines without consciousness
* Allows functional evaluation of systems
* Avoids unsolvable debates about mind

---

### **Chapter 6: Computational Implementation of Agency**

Relates the theory to real systems:

* Draws on information theory (Shannon, Dretske)
* Critiques the view of software as mere symbol manipulation
* Defends **semantic coupling** with the environment as the basis of agency

---

### **Chapter 7: Agency in Contemporary Machines**

Applies the theory to current systems:

* **AlphaGo**, **GPT**, autonomous robots
* If they use representations and adaptive control, they can be considered **functional agents**
* Implies redesign of regulation and safety frameworks

---

### **Chapter 8: Biology and Brains**

Is a brain or biological substrate necessary?

* No. What matters is functional organization.
* Incorporates ideas from dynamic systems (Juarrero, Varela, Maturana)

> Living and artificial systems can share agency structures if they process and integrate meaningful information.

---

### **Chapter 9: Information, Communication, and Control**

Expands the theory using:

* Cybernetics
* Feedback
* Adaptive control

> Agency as a property of systems that **self-regulate using meaningful environmental information**.

---

### **Chapter 10: Responsibility for Machine Actions**

Question: if a machine is an agent, can it be responsible?

* Examines moral responsibility theories (intentionality, consequences, autonomy)
* Proposes new frameworks to distribute responsibility when a machine acts autonomously

---

### **Chapter 11: Agents in the Social World**

Explores moral status and social relationships:

* Do they deserve rights?
* Can we have obligations toward machines?

Introduces the concept of **moral patience**: entities to which we owe ethical care even if they lack full consciousness.

---

## General Conclusion

The book does not claim that machines have minds, but rather that **some should be treated as agents**. It proposes a minimalist, practical, and applicable theory to evaluate artificial systems from a functional, ethical, and social perspective.

> **Philosophy, science, technology, and regulation must work together** to design future coexistence with non-human agents.

## Final Keys

1. **Agency** is a more productive concept than intelligence for understanding machines.
2. Some machines **already qualify as agents**.
3. Consciousness or biology are not required: functional organization is enough.
4. We need **new legal and ethical frameworks**.
5. **Moral status is not binary**; there may be degrees.
6. Myths and narratives shape our understanding of AI.
7. Philosophy is essential to clarify, argue, and guide the debate.
8. Internal representations are key for goal-directed action.
9. Proactive design must anticipate social consequences of autonomous systems.

## Coda

Agency is not the end of the debate, but it is a **solid and practical new beginning**.
